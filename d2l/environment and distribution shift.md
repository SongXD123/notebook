# 协变量偏移（covariance shift）

假设输入的分布$P(x)$可能随时间改变，但标记函数，即条件分布$P(y|x)$的分布不会随时间改变

如：区分猫和狗的图片，训练时使用真实的猫和狗的照片，测试时却对卡通图片进行分类。

因此，在一个看起来与测试集有着本质不同的数据集上进行训练，而不考虑如何适应新的情况，不是一个好主意。

统计学家称这种协变量变化是因为问题的根源在于特征分布的变化（即协变量的变化）。数学上，我们可以说$P(x)$改变了，但$P(y∣x)$保持不变。尽管它的有用性并不局限于此，当我们认为$x$导致$y$时，协变量移位通常是正确的假设。

### 改正

​	假设通过标记的数据$(x_i,y_i)$来估计概率$P(y|x)$，而训练集观测值$x_i$是从错误的源分布$q(x)$得到的，而不是目标分布$p(x)$，我们可以通过以下真实损失函数改正
$$
\int\int l(f(x),y)p(y|x)p(x)dxdy=\int\int l(f(x),y)q(y|x)q(x)\frac{p(x)}{q(x)}
$$
​	用$\beta_i\stackrel{\mathrm{def}}{=}\frac{p(x_i)}{q(x_i)}$重新加权每个数据示例，继而用加权经验风险最小化训练模型
$$
minimize{\frac{1}{n}}\displaystyle\sum^{n}_{i=1}\beta_il(f(x_i),y_i)
$$

### 如何计算$\beta_i$

前提：从两个分布中获取样本

* $p$：true distribution：访问数据
* $q$：wrong distribution：容易获得
* 只需要输入特征分布$x\sim{p(x)}$，而不需要标签分布$y\sim{p(y)}$

**用逻辑回归估计$\beta_i$** 

用逻辑回归区分从$p(x)$提取的数据和从$q(x)$提取的数据。如果无法区分这两个分布，那么这意味着相关的实例同样可能来自这两个分布中的任何一个。任何容易区分的数据都需要加权。

为简单起见，假设从分布$p(x)$和$q(x)$获得了相同数量的实例，用$z$表示标签，将从$p$中获得的数据标记为1，从$q$中获得的数据标记为-1。混合数据集中的概率如下
$$
P(z=1|x)=\frac{p(x)}{p(x)+q(x)},
因此\frac{P(z=1|x)}{P(z=-1|x)}=\frac{p(x)}{q(x)}
$$
因此，如果用逻辑回归，$P(z=1|x)=\frac{1}{1+exp(-h(x))}$($h$是一个参数化函数)，它将遵循
$$
\beta_i=\frac{1/(1+exp(-h(x_i)))}{exp(-h(x_i))/(1+exp(-h(x-i)))}=exp(h(x_i))
$$
因此，还需要解决两个问题：

* 区分从两个分布中提取的数据
* 使用加权经验风险最小化解决问题

由此，校正算法如下：

​	假设我们有一组训练数据$\{(x_i,y_i),...,(x_n,y_n)\}$并且没有标记过的测试集$\{u_1,...,u_m\}$，为简便起见，假设$x_i$（对于所有$1\leq{i}\leq{n}$，来自源分布，$u_i$（对于$1\leq{i}\leq{m}$）来自目标分布，修正协变量偏移的典型算法：

* 产生双分类训练集：$\{(x_1,-1),...,(x_n,-1),(u_1,1),....,(u_m,1)\}$
* 通过逻辑回归训练双分类器，得到回归函数$h$
* 加权值$\beta_i=exp(h(x_i))$或对于某些常数更好的$\beta_i=min(exp(h(x_i)),c)$
* 用$\beta_i$加权训练数据集$\{(x_i,y_i),...,(x_n,y_n)\}$

**注意**：以上方法依赖关键假设：需要目标(例如，测试时间)分布中的每个数据例子在训练时间具有非零的出现概率。如果有一个数据$p(x)>0$但$q(x)=0$，相应的权值就会无穷大

# 标签偏移

当我们认为导致偏移的是标签$P(y)$上的边缘分布的变化，但类的条件分布$P(x|y)$不变的话，就会出现相反的问题。当我们认为$y$导致$x$时，标签偏移是一个合理的假设。例如，通常我们希望根据症状来预测诊断结果，即使诊断的相对患病率随时间的推移而变化。在这种情况下，我们认为诊断引起的表现，即疾病引起症状，因此标签偏移是合理的。在某些退化情况下，标签偏移和协变量偏移假设可以同时成立。例如，当真正的标签函数是确定的，那么协变量偏移将始终满足，即使$y$导致了$x$，有趣的是，在这种情况下，使用来自标签偏移假设的方法通常是有利的。这是因为这些方法倾向于操作看起来像标签的对象，这（在深度学习中）与处理看起来像输入的对象（在深度学习中）相比相对容易一些。
假设处理$k$分类问题，$q$和$p$是源分布和目标分布，标签的分布随时间变化：$q(y)\neq{p(y)}$，但类条件分布保持不变：$q(x|y)=p(x|y)$，如果源分布$q(y)$是错误的，可以通过如下式子修正
$$
\int\int{l(f(x),y)p(x|y)p(y)dxdy=\int\int{l(f(x),y)q(x|y)\frac{p(y)}{q(y)}}dxdy}
$$
这里，关键在于计算$\beta_i\stackrel{\mathrm{def}}{=}\frac{p(y_i)}{q(y_i)}$

标签转移的一个利好之处在于如果我们有一个合理的好的源分布模型，我们就可以得到这些权重的一致估计，而不必处理环境维度。深度学习中，输入往往是像图像一样的高纬数据，而标签往往是像类别这样的简单对象。

为了估计目标标签分布，首先用相当好的现成分类器（通常根据训练数据进行训练），并使用验证集（同样来自训练分布）计算混淆矩阵$\pmb{C}$，这是简单的$k \times k$矩阵，每列对于标签类别（真实的），美好对于模型的预测类别。每个单元格的$c_{ij}$是验证集上总预测的一部分，其中真正的标签是$j$，而我们模型预测的是$i$，

现在，我们不能直接计算目标数据上的混淆矩阵（？），因为我们无从得到自然状态下（in the wild)样本的标签。我们所能做的是，在测试时对模型预测作平均，产生平均模型输出$\mu(\pmb{\hat{y}})\in\mathbb{R}^k$，第$i$个元素$\mu(\hat{y_i})$是我们的模型在测试集上预测的总预测分数。

事实证明，在一些温和条件下，如果我们的分类器从一开始就很准确，且目标数据只包含我们以前见过的类别，并且如果标签偏移假设成立，我们可以通过简单的线性系统$\pmb{C}p(\pmb{y})=\mu(\hat{\pmb{y}})$来估计测试集标签分布，而由于我们在源数据上观测，所以$q(y)$容易获得

# 概念偏移

标签本身的定义发生变化，即$P(y|x)$是逐渐变化的。这个问题不容易解决。例如，当问题突然从区分猫到区分黑白动物，可能没有比从头开始收集数据再训练更好的方法，但幸运的是，如此极端的偏移很少，相反，通常偏移都是逐渐发生的。如

* 在计算广告中，新产品推出，旧产品变得不那么受欢迎。这意味着广告的分布和它们的受欢迎程度逐渐变化，任何点击率预测器都需要随之逐渐变化。
* 由于环境磨损，交通摄像头镜头逐渐退化，逐渐影响图像质量
* 新闻内容逐渐变化(即大部分新闻保持不变但出现新的故事)。

在这种情况下，可以使用现有网络权重，简单地用新数据执行一些更新，而不是从头训练





<center><center>